//
//  ResultViewController.swift
//  SmartAI
//
//  Created by Hamlit Jason on 2022/11/18.
//

import UIKit
import Vision
import SnapKit

protocol ResultViewControllerProtocol {
    func didTapImageView()
}

class ResultViewController: UIViewController, ResultViewControllerProtocol {
    var delegate: ResultViewControllerProtocol?
    
    // MARK: - Properties
    var image: UIImage? {
        // NOTE: - MVVM Î¶¨Ìå©ÌÜ†ÎßÅ Í≥†ÎØº. Ìï†Í≤å ÎÑàÎ¨¥ ÎßéÏïÑÏöî Í∑ºÎç∞ „Ö†„Ö†
        didSet {
            guard let image else { return }
            // NOTE: - ÏÑúÎ≤ÑÏóêÏÑú Í≤∞Í≥ºÍ∞Ä ÎÇ¥Î†§Ïò§ÎäîÎç∞ ÏãúÍ∞ÑÏù¥ Ïò§ÎûòÍ±∏Î¶º (ÌÖåÏä§Ìä∏ Í≤∞Í≥º Ï†ÅÏñ¥ÎèÑ 5Ï¥à Ïù¥ÏÉÅ)
            if NetworkMonitor.shared.isConnected {
                APIManager.shared.uploadImage(for: image) { result in
                    switch result {
                    case .success(let banana):
                        self.answerLabel.text = banana.bananaClasses[banana.argmax]
                        var resultText: String = ""
                        banana.bananaClasses.forEach { key, value in
                            if let probability = banana.probability[key] {
                                resultText += String(format: "  (%.2f) %@", probability, value)
                            }
                        }
                        dump("‚òÉÔ∏è \(resultText)")
                    case .failure(let error):
                        break
                    }
                }
            }
            
            self.updateClassifications(for: image)
            self.resultImageView.image = image
        }
    }
    private lazy var coreMLRequest: VNCoreMLRequest = {
        do {
            let model = try VNCoreMLModel(for: BananaClassification().model)
            
            let request = VNCoreMLRequest(model: model) { [weak self] request, error in
                guard let self else {
                    print("üö® guardÎ¨∏Ïóê Í±∏Î†∏ÎÑ§Ïöî.")
                    return
                }
                self.processClassifications(for: request, error: error)
            }
            
            request.imageCropAndScaleOption = .centerCrop
            return request
        } catch {
            fatalError("üö® \(error.localizedDescription)")
        }
    }()
    
    // MARK: - function
    private func processClassifications(for request: VNRequest, error: Error?) {
        DispatchQueue.main.async {
            guard let results = request.results else {
                print("üö® \(error?.localizedDescription)")
                return
            }
            
            let classifications = results as! [VNClassificationObservation]
            
            if classifications.isEmpty {
                print("üö® Í≤∞Í≥ºÎ•º Ï∂îÏ∂úÌñàÏßÄÎßå ÎπÑÏñ¥ÏûàÏñ¥Ïöî.")
            } else {
                let classifications = classifications.prefix(4)
                dump("üíïclassifications \(classifications)")
                let descriptions = classifications.map { classification in
                    return String(format: "  (%.2f) %@", classification.confidence, classification.identifier)
                }
                
                self.resultLabel.text = descriptions.joined(separator: "\n")
                self.answerLabel.text = classifications.prefix(1)
                    .map { classification in
                        return String(format: "%@", classification.identifier)
                    }.joined()
            }
        }
    }
    
    private func updateClassifications(for image: UIImage) {
        
        let orientation = CGImagePropertyOrientation(image.imageOrientation)
        guard let ciImage = CIImage(image: image) else {
            print("üö® \(#function)")
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            let handler = VNImageRequestHandler(ciImage: ciImage, orientation: orientation)
            
            do {
                try handler.perform([self.coreMLRequest])
            } catch {
                print("üö® \(error.localizedDescription)")
            }
        }
    }
    
    func didTapImageView() {
        print("didTapImageView")
    }
    
    // MARK: - Life Cycle
    override func viewDidLoad() {
        super.viewDidLoad()
        
        view.backgroundColor = .white
        configureUI()
    }
    
    // MARK: - UIComponents
    lazy var resultImageView: UIImageView = {
        $0.layer.cornerRadius = 12
        $0.clipsToBounds = true
        return $0
    }(UIImageView())
    
    lazy var answerLabel: UILabel = {
        $0.textColor = .green
        $0.textAlignment = .center
        $0.font = .pretendardFont(size: 16, style: .regular)
        
        return $0
    }(UILabel())
    
    lazy var resultLabel: UILabel = {
        $0.textColor = .black
        $0.textAlignment = .center
        $0.numberOfLines = 0
        $0.font = .pretendardFont(size: 22, style: .medium)
        
        return $0
    }(UILabel())
}

extension ResultViewController {
    func configureUI() {
        view.addSubview(resultImageView)
        resultImageView.snp.makeConstraints {
            $0.leading.trailing.top.equalToSuperview().inset(20)
            $0.height.equalTo(view.frame.width - 40)
        }
        
        resultImageView.addSubview(answerLabel)
        answerLabel.snp.makeConstraints {
            $0.center.equalToSuperview()
        }
        
        view.addSubview(resultLabel)
        resultLabel.snp.makeConstraints {
            $0.top.equalTo(view.snp.centerY).inset(20)
            $0.leading.trailing.equalToSuperview().inset(20)
            $0.bottom.equalTo(view.safeAreaLayoutGuide)
        }
    }
}
